[2024-01-31 13:27:43,137] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_postgresql.aggregate_dim_table manual__2024-01-31T13:27:27.422828+00:00 [queued]>
[2024-01-31 13:27:43,143] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_postgresql.aggregate_dim_table manual__2024-01-31T13:27:27.422828+00:00 [queued]>
[2024-01-31 13:27:43,143] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2024-01-31 13:27:43,144] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2024-01-31 13:27:43,144] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2024-01-31 13:27:43,155] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): aggregate_dim_table> on 2024-01-31 13:27:27.422828+00:00
[2024-01-31 13:27:43,160] {standard_task_runner.py:52} INFO - Started process 6117 to run task
[2024-01-31 13:27:43,164] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl_postgresql', 'aggregate_dim_table', 'manual__2024-01-31T13:27:27.422828+00:00', '--job-id', '114', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp07jaofrq', '--error-file', '/tmp/tmpgk3rmfj1']
[2024-01-31 13:27:43,165] {standard_task_runner.py:80} INFO - Job 114: Subtask aggregate_dim_table
[2024-01-31 13:27:43,204] {task_command.py:369} INFO - Running <TaskInstance: etl_postgresql.aggregate_dim_table manual__2024-01-31T13:27:27.422828+00:00 [running]> on host d99f9e65d396
[2024-01-31 13:27:43,251] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_postgresql
AIRFLOW_CTX_TASK_ID=aggregate_dim_table
AIRFLOW_CTX_EXECUTION_DATE=2024-01-31T13:27:27.422828+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-01-31T13:27:27.422828+00:00
[2024-01-31 13:27:46,243] {logging_mixin.py:115} INFO - Successfully install sqlalchemy
[2024-01-31 13:27:46,294] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/etl_dag.py", line 177, in _aggregate_dim_table
    mysql_engine = create_engine(mysql_url)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 298, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 548, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/mysql/mysqlconnector.py", line 129, in dbapi
    from mysql import connector
ModuleNotFoundError: No module named 'mysql'
[2024-01-31 13:27:46,303] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=etl_postgresql, task_id=aggregate_dim_table, execution_date=20240131T132727, start_date=20240131T132743, end_date=20240131T132746
[2024-01-31 13:27:46,312] {standard_task_runner.py:97} ERROR - Failed to execute job 114 for task aggregate_dim_table (No module named 'mysql'; 6117)
[2024-01-31 13:27:46,349] {local_task_job.py:156} INFO - Task exited with return code 1
[2024-01-31 13:27:46,376] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
